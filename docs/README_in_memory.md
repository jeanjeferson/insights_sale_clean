# Pipeline em Mem√≥ria - Documenta√ß√£o

## Vis√£o Geral

O `InMemoryForecastPipeline` √© uma implementa√ß√£o otimizada que executa todo o processo de forecasting em mem√≥ria, eliminando opera√ß√µes de I/O desnecess√°rias e fazendo upload √∫nico para FTP ao final.

## Vantagens

- **Performance**: Elimina salvamento/recarregamento de CSVs
- **Efici√™ncia**: Reutiliza dados carregados em mem√≥ria
- **Simplicidade**: Um √∫nico ponto de entrada
- **Escalabilidade**: F√°cil adicionar novos tipos de forecast
- **Manutenibilidade**: C√≥digo mais limpo e organizado

## Uso

### Modo Tradicional (com arquivos locais)
```bash
python run_all_pipelines.py
```

### Modo Mem√≥ria (sem arquivos locais)
```bash
python run_all_pipelines.py --memory
```

### Pipeline espec√≠fico
```bash
python run_all_pipelines.py vendas
python run_all_pipelines.py empresa
```

### Ajuda
```bash
python run_all_pipelines.py --help
```

## Estrutura de Dados

### Carregamento de Dados
```python
data = {
    'database': 'nome_do_banco',
    'clientes': {
        'result': resultado_extracao,
        'success': True/False
    },
    'vendas': {
        'data': DataFrame,
        'success': True/False
    },
    'vendas_empresa': {
        'data': DataFrame,
        'success': True/False
    },
    'loaded_at': datetime
}
```

### Resultados Consolidados
```python
results = {
    'database': 'nome_do_banco',
    'timestamp': '2024-01-01T00:00:00',
    'vendas': {
        'success': True/False,
        'historical': DataFrame,
        'forecasts': {30: DataFrame, 60: DataFrame, 90: DataFrame},
        'metrics': {30: dict, 60: dict, 90: dict},
        'consolidated': DataFrame
    },
    'vendas_empresa': {
        'success': True/False,
        'forecasts_by_company': {empresa: DataFrame},
        'metrics_by_company': {empresa: dict},
        'consolidated': DataFrame,
        'summary_metrics': dict
    },
    'summary': {
        'vendas_success': True/False,
        'vendas_empresa_success': True/False,
        'total_companies': int,
        'overall_quality': str
    }
}
```

## Fluxo de Execu√ß√£o

1. **Carregamento**: Dados extra√≠dos diretamente do banco via `SimpleDataExtractor`
2. **Processamento Vendas**: Forecast univariado com m√∫ltiplos horizontes
3. **Processamento Vendas por Empresa**: Forecast por empresa com filtros de qualidade
4. **Consolida√ß√£o**: Unifica√ß√£o de todos os resultados
5. **Prepara√ß√£o FTP**: Cria√ß√£o de arquivos em mem√≥ria para upload
6. **Upload**: Envio √∫nico para servidor FTP

## Configura√ß√£o

O pipeline utiliza o arquivo `config/config_databases.yaml` para obter a lista de databases a processar.

## Tratamento de Erros

- **Carregamento**: Falhas individuais n√£o interrompem o pipeline
- **Processamento**: Erros s√£o logados e continuam com pr√≥ximos databases
- **Upload**: Falhas de upload s√£o reportadas mas n√£o interrompem o processo

## M√©tricas de Qualidade

### Vendas
- MAPE (Mean Absolute Percentage Error)
- MAE (Mean Absolute Error)
- RMSE (Root Mean Square Error)
- sMAPE (Symmetric MAPE)
- R¬≤ (Coefficient of Determination)
- Bias

### Vendas por Empresa
- M√©tricas individuais por empresa
- M√©tricas consolidadas (m√©dia, melhor, pior)
- Contagem de empresas processadas

## Classifica√ß√£o de Qualidade

- üü¢ **EXCELENTE**: MAPE ‚â§ 5%
- üü° **BOA**: MAPE ‚â§ 15%
- üü† **REGULAR**: MAPE ‚â§ 30%
- üî¥ **BAIXA**: MAPE > 30%

## Arquivos Gerados para FTP

### Vendas
- `{database}/vendas/vendas_historicas.csv`
- `{database}/vendas/previsoes_vendas_30.csv`
- `{database}/vendas/previsoes_vendas_60.csv`
- `{database}/vendas/previsoes_vendas_90.csv`
- `{database}/vendas/vendas_consolidadas.csv`

### Vendas por Empresa
- `{database}/vendas_empresa/previsao_vendas_empresa.csv`
- `{database}/vendas_empresa/metricas_vendas_empresa.csv`

## Exemplo de Uso Program√°tico

```python
from pipelines.in_memory_forecast_pipeline import InMemoryForecastPipeline

# Inicializar pipeline
pipeline = InMemoryForecastPipeline()

# Executar para um database espec√≠fico
result = pipeline.run_complete_pipeline('nome_do_banco')

# Executar para todos os databases
results = pipeline.run_all_databases()

# Verificar resultados
if results['success']:
    print(f"Processados: {results['successful_count']}/{results['total_count']}")
    print(f"Empresas: {results['metadata']['total_companies']}")
    print(f"Qualidade: {results['metadata']['overall_quality']}")
```

## Logs

O pipeline gera logs detalhados com prefixo `[in_memory]` para facilitar o debugging e monitoramento.

## Considera√ß√µes de Mem√≥ria

- Dados s√£o carregados uma √∫nica vez por database
- DataFrames s√£o reutilizados durante o processamento
- Arquivos FTP s√£o criados em buffers de mem√≥ria
- Garbage collection √© autom√°tico ap√≥s upload

## Troubleshooting

### Erro de Mem√≥ria
- Reduzir n√∫mero de databases processados simultaneamente
- Ajustar filtros de qualidade para reduzir empresas processadas

### Erro de Upload FTP
- Verificar conectividade com servidor FTP
- Validar credenciais e permiss√µes
- Verificar espa√ßo em disco no servidor

### Erro de Dados
- Verificar conectividade com banco de dados
- Validar estrutura dos dados extra√≠dos
- Verificar configura√ß√µes de filtros de qualidade
